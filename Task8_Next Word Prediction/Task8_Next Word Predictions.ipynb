{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> LetsGrowMore (LGMVIPFEB2022) - Data Science Intern </h1>\n",
    "<h2> Author Name : Sourabh Vijay Dohare </h2>\n",
    "<h2> Task8 : Next Word Prediction</h2>\n",
    "<h2> Level : Intermediate </h2>\n",
    "<h2>Language : Python </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Importing Libraries</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Preprocessing the Data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyle This eBook is for the use of anyone anywhere at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this eBook or online at www.gutenberg.net Title: The Adventures of Sherlock Holmes Author: Arthur Conan Doyle Release Date: November 29, 2002 [EBook #1661] Last Updated: May 20, 2019 Language: English Character set en\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"1661-0.txt\", \"r\", encoding = \"utf8\")\n",
    "\n",
    "# store file in list\n",
    "lines = []\n",
    "for i in file:\n",
    "    lines.append(i)\n",
    "\n",
    "# Convert list to string\n",
    "data = \"\"\n",
    "for i in lines:\n",
    "  data = ' '. join(lines) \n",
    "\n",
    "#replace unnecessary stuff with space\n",
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')  #new line, carriage return, unicode character --> replace by space\n",
    "\n",
    "#remove unnecessary spaces \n",
    "data = data.split()\n",
    "data = ' '.join(data)\n",
    "data[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Finding the length of the data</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "573660"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Setting up Tokenizer</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[142, 4680, 1, 986, 5, 125, 33, 46, 556, 2164, 2165, 27, 987, 14, 22]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "\n",
    "# saving the tokenizer for predict function\n",
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))\n",
    "\n",
    "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
    "sequence_data[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108958"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8624\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Length of sequences are:  108955\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 142, 4680,    1,  986],\n",
       "       [4680,    1,  986,    5],\n",
       "       [   1,  986,    5,  125],\n",
       "       [ 986,    5,  125,   33],\n",
       "       [   5,  125,   33,   46],\n",
       "       [ 125,   33,   46,  556],\n",
       "       [  33,   46,  556, 2164],\n",
       "       [  46,  556, 2164, 2165],\n",
       "       [ 556, 2164, 2165,   27],\n",
       "       [2164, 2165,   27,  987]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences = []\n",
    "\n",
    "for i in range(3, len(sequence_data)):\n",
    "    words = sequence_data[i-3:i+1]\n",
    "    sequences.append(words)\n",
    "    \n",
    "print(\"The Length of sequences are: \", len(sequences))\n",
    "sequences = np.array(sequences)\n",
    "sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in sequences:\n",
    "    X.append(i[0:3])\n",
    "    y.append(i[3])\n",
    "    \n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data:  [[ 142 4680    1]\n",
      " [4680    1  986]\n",
      " [   1  986    5]\n",
      " [ 986    5  125]\n",
      " [   5  125   33]\n",
      " [ 125   33   46]\n",
      " [  33   46  556]\n",
      " [  46  556 2164]\n",
      " [ 556 2164 2165]\n",
      " [2164 2165   27]]\n",
      "Response:  [ 986    5  125   33   46  556 2164 2165   27  987]\n"
     ]
    }
   ],
   "source": [
    "print(\"Data: \", X[:10])\n",
    "print(\"Response: \", y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>MODEL SETUP</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=3))\n",
    "model.add(LSTM(1000, return_sequences=True))\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation=\"relu\"))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 3, 10)             86240     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 3, 1000)           4044000   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 1000)              8004000   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8624)              8632624   \n",
      "=================================================================\n",
      "Total params: 21,767,864\n",
      "Trainable params: 21,767,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAIjCAYAAAAnXHa0AAAABmJLR0QA/wD/AP+gvaeTAAAgAElEQVR4nO3dQWgbZ/4+8Gdiy9lD07jNxjY0yW7S1EkpxAS2kPRQ0zSwhDKih7qt7ThOl7aMD7s0/+ayi0QOge1FostuwcEuW0qRJeIeik3Zkw2/HCJTCCgsuxu5aYqcmEbKhpXSXmInef8HdyYjaSSPZGnG9vf5gMB6NZr3O6N59I5eyZKmlFIgIhG2+F0AEXmHgScShIEnEoSBJxKktbTh9u3bOHPmDB4+fOhHPUTUAC0tLfj444/R1dVV1F42ws/OziKRSHhWGBE1XiKRwOzsbFl72QhvunjxYlMLIqLm0TTNsZ2v4YkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBFm3gc/lckgkEggGg76u32m5cDiMcDjclLrc8Lt/2rgq/j+8386dO4cLFy74vv5m17ERFQoFtLe3o5ZvOK/0/9l+fEt6af3rqbamUyVisZhyaPYFgKbW4nb9za5jo5mamqprf+TzeWtf5vP5JlTmjlP92Wx2XdTWKABULBYra1+3p/S0PhUKBYyPj9d13+3btzv+7aVK9Xd0dFh/+1WbFxoW+Fwuh2g0Ck3TEAwGre/TKn0NPD09DU3TMDIygoWFBQAr379V2lZp3W6WsfdvKhQKVj/BYBDz8/OO27HacqXbU2n7gsFgWZ2zs7MIBoPQNA3RaBS5XG7V/eq0nbX2n8vlMD09bS0zPj5u7Uv79mmaZl0qtUUiEUxPTxfdBtQ/r7Be6q+F+aRh3j8cDhcdf+YlGo1a97HfZt+uSpkxt7dQKGBkZKRxczalQ349p/TZbFbpuq7i8bhSSqmZmRkFQKVSKaXrunWqlEqllFJKJZNJBUAZhqGSyaRSSqlMJmO12U9LAFjLmP0AUNls1lX/Jl3XlWEY1ulaPB53PFVfbTn79pRer7Yt5mmkuYx9vbXs73r6t/djLpPP55VhGAqASqfT1n4srcdcl73NqeZQKKRCodCq9Zfed73UX629lNlvNpstq9V+bJfSdd06bt1mJplMqlQq5bi+alDhlL4hgTcP3tIOzQPAaUe6aXNaJp1OKwBqbGzMdf9m2MwDQ6ni15Mmt8u5qdPtMpFIRNWqUf2nUqmyGupdV721r6f63W5XKBRyHJhMkUhEAVCZTKaoVjPcSrnPTL3zCU0NvP0ZqfRiL760oEY9MKv1bz4jr7Yet8vVEzinddcbnEYFvtHrqqf29VR/rduVyWSscNvvZz4R2QelSCRS9ARQT2Zq0dTAr1acHw+ym/oa1Z+bbTEPAvNZ3ml0couBb079tWzX2NiY0nXdOuMsvZ/5BJ/P562XH7X01azAN3SWvtJEWDMYhuFr/7Xq6enB1NQUFhcXrYmeeDyODz/80O/SHPflRuJV/SMjIwBWJpnff/99fPLJJ+ju7q5a0z/+8Q9cunQJw8PDjst5fsyWPgPUM8KPjY0pYOX1h/maI5vNWqMXGvisXjpSuunfvN0+iee0frfLuamztG1qaqph7+/W07/TMuboNDU1teZ11Vv7eqq/2nYlk0nrmHO7PnOU13W97LZ6MlMLVBjhGxJ4++yo/ZLJZBw/0GBvs89alraZr3NmZmasZXRdLzsNrta/Uo9nanVdt9rMWVHg8Yyqm+VK63TaPvtEn7ktTvXZ11nPvq6nf/OgzefzKhQKlR2MpTPf5qyzfT/Z3ykxHws3s/ROH7xZL/U7zfCbzHWYA4F5/0wmU3RKX/o4mvezv5Y3uc1MvZoaeKVWwhIKhawdawamdINqaVNqJXDmDjYMwwq/2/7tt5sHgxky820R+wO12nKVgrvatpS+3VIaerfq7d/8217H2NhY2VlHJpOxbjdHztL9ZJ5lhUIhq221wK9Wt5/1u63N7Kv0/uasfekxZ/Ztf9entNbVMuN0duBG0wNP1aXTaccDwhwhmm2tI4bfNmL9TpN1XqkUeH601gOJRALd3d3Ys2dP2W2dnZ2Ix+M+VEXNdvHiRfT19fldRhEG3gMTExMYHx8v+6jt/Pw8Ll68iLfffrup/ds/wlvPx3n9tpHqD4fDRR+hPXbsmN8lFWHgPfDFF19g27Zt+Oijj4o+f33r1i289957AIo/813tUo/Ozk7HvzeKjVS/eRY3NjaG8+fP+1xNOe3n833LxMQEBgcHUdJMRBuIpmmIxWIYGBgoaucITyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyRIxV+PffPNN72sg4g8UPbvsbdv38aZM2fw8OFDv2qiJrt27RoA4ODBgz5XQs3S0tKCjz/+GF1dXUXtZYGnzW9wcBAAEIvFfK6EvMbX8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIJoSinldxHUPIuLi3jttdfQ3t5utc3PzwMAuru7rbZ8Po/Z2Vk8/fTTntdI3mn1uwBqrrt37+Lq1auOt/3www9F1xcXFxn4TY4jvADPPfccrl+/XnWZ/fv349tvv/WoIvILX8MLcPr0aQQCgYq3BwIBnD592ruCyDcc4QW4ceMGnn322arLfPfdd9i3b59HFZFfOMILsG/fPhw+fBiappXdpmkaDh8+zLALwcALMTw8jJaWlrL2lpYWDA8P+1AR+YGn9ELcvn0bzzzzDB49elTUvmXLFiwuLqKrq8unyshLHOGF6OrqQm9vb9Eo39LSgt7eXoZdEAZekMHBQVdttHnxlF6QfD6Pjo4OLC8vA1h5Oy6XyxV9Co82N47wgrS3t+PEiRNobW1Fa2srTpw4wbALw8ALMzQ0hAcPHuDBgwcYGhryuxzymGefpU8mk7h165ZX3VEFS0tL1t/379/H5OSkj9UQAOzatQtHjx71pC/PXsM7feiDiFZ4NZXm6X/LxWIxDAwMeNkl0bo2MTHh6TslfA1PJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTySIqMDncjkkEgkEg0Ff1++0XDgcRjgcbkpdfuN+Xz9E/XrsuXPncOHCBd/X3+w6auH2i0nW8gUN3O/rh6ffeLMevgDDPMCbtdlu19/sOmpRKBSsL7MsrWd+fh4HDhxYc53c787ML8Dwqh5Rp/TkbPv27RVv6+7u9rASarZ1HfhcLodoNApN0xAMBjE7O2u121+LTU9PQ9M0jIyMYGFhAQCQSCTK2iqt280y9v5NhULB6icYDGJ+ft5xO1ZbrnR7Km1fMBgsq3N2dhbBYBCapiEajSKXyxXdvpbXqKWjIff7Y6vt93VLeQSAisVirpfPZrNK13UVj8eVUkrNzMwoACqVSild1xUA67pSSiWTSQVAGYahksmkUkqpTCZjtdnrAGAtY/YDQGWzWVf9m3RdV4ZhqHw+r5RSKh6PW+u3W205+/aUXq+2LVNTU0XL2NdrrisUCqlQKLTq/i6t2+yvdDu4393td7disVjN91mLdRt4cyeWrsM8eJ12rps2p2XS6bQCoMbGxlz3bz7o6XTauj2fz5et3+1ybup0u0wkElG1sh+w1Q5e7vfG7ncG/mf2Z1ung7CRB55T+2r9G4bhaj1ul6vnwHNadz2jjNP9nEZ4t3W53R6ndmn7nYG3LV9tRzT7wKun/0b252ZbUqmUAmCd/prX1zLCl7a5XY77fWOM8Ov+ffj5+XnPZooNw/C1/1r19PRgamoK8/Pz0DQNuq4jHo/j7bffbsj6lUdvFXG/e8irZxbUOMKPjY0pYOW1mznpks1mrWdRNHCkKX3GdtO/ebt9Mslp/W6Xc1NnadvU1JRV21o59WfKZDJNmTvhfucpvSWbzVo72n7JZDJFt9kPCrPNnPV1ajNfI87MzFjL6LpedjpWrX+lHr/G1XXdajNnlIHHs7puliut02n77BNO5rY41Wdfp1LuZumdJrNMmUzGmoHnfne/391i4G3MkcXcmeYDV7qja2lTauWBNw9AwzCsg9Bt//bbzQkc88E231KyP/CrLVfpAFptW0rfoiw9+JRaPfCr9W0PAPe7+/3ulteBF/fR2s1kfn4ev/jFL7Bnz56y9kZ8HJacNXK/86O15EoikUB3d3fZQQcAnZ2diMfjPlS1+W30/b7uZ+nJ2cTEBH788Uf89re/LTr45ufn8X//93947733fKxu89ro+50j/Ab1xRdfYNu2bfjoo4+gaRo0TUM4HMatW7fW/UG3kW30/c7X8EQ+4mt4ImoaBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQT/8ffnJyEoFAwMsuida1yclJT/vz7N9jt27diqWlJS+6ItpQ2tracP/+fU/68izwtH4MDg4CAGKxmM+VkNf4Gp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkgQBp5IEAaeSBAGnkiQVr8LoOZaWlrCxMQElpaWrLbr168DAMbGxqy2trY2nDx5Eq2tPCQ2M00ppfwugprn0qVL6O3tBQAEAgEAgPmQa5oGAFheXgYAfPPNN3jxxRd9qJK8wsBvcktLS9i5cyfu3btXdbknn3wSd+7cQVtbm0eVkR/4Gn6Ta2trw1tvvWWN7k4CgQDeeusthl0ABl6AwcFB67TdyfLyMgYGBjysiPzCU3oBHj16hK6uLty5c8fx9p07d+L27dvYsoXP/5sdH2EBtmzZgqGhIcdT9ra2NgwNDTHsQvBRFmJgYKDorTnT0tIST+cF4Sm9IPv27cP3339f1LZ3717cuHHDp4rIaxzhBTl16lTRbH0gEMDQ0JCPFZHXOMILkk6ncfDgwaK2a9eu4cCBAz5VRF7jCC/IgQMHcOjQIWiaBk3TcOjQIYZdGAZemOHhYSvww8PDfpdDHuMpvTC3bt3C7t27AQA3b97Erl27fK6IvMQR3kEoFLJGwc12McMOALt37/a9nmZdQqGQj0fQ+sX/hXTw/fffIxAIIBaL+V1KU9y7dw+apmHbtm1+l9IUg4ODZW8/0goGvoK+vj709fX5XQbV4auvvvK7hHWLp/REgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8A2Qy+WQSCQQDAb9LoWoKga+Ac6dO4f+/n5MT0+7vk+hULB+rrnZKn0rTDVzc3MYGRmBpmkYGRnB7OxsWc1r/Vaaubm5qv3XUi+5w8A3wOjoaM33uXTpUhMqcaaUQjabta7n83lU+yrDubk5HD16FL29vVBKYXR0FDt27HD8Dvt4PA6llHWx92le4vG41ZbJZKxlPv/884o12G/LZrNV6yX3GHgfFAoFjI+Pe9pnR0eH9ff27durLmuG7e2337baenp6cP78+bJl7ctUcuLECevvPXv2AAAikQguXLiAhYWFsuUXFhawf/9+x9ppbRj4JopGo9A0DePj48jlctZpaSQSsU7/zdPV0nmA6elp63TaDEUikShrA4BwOIxwONywuhcXFwEAV69eLWrv6ekpum4fravZvn172bLHjx8HAFy+fLls+cuXL1u3U4MpKjMwMKAGBgZqug8AZd+dkUhEZTIZpZRS+XxehUKhottLl9d13WpLpVJKKaWSyaQCoAzDUMlkUimlVCaTsdpMoVBIhUKhmmusJJVKWcuOjY2pfD6/6n1q6cO83TAMx2XNbXNbb6l6Hj8pGHgHjQg8AJXNZq3r2Wy2auDX2lZPjdWk02krkABUPB53FfxaAj8zM6MAWE9mSq082czMzNRcrx0DXxlP6ZvEMAx0dnYikUigUCigo6NjQ008dXd3Y3R0FMlkEoZhoL+/H+3t7TW9E7GaY8eOASieoPvyyy+tdmo8Br5Jzpw5A13XraBEo1G/S6rLkSNHrODruo5gMNjQ0MfjcWvyLpfL4YUXXmjYuqkcA98k3d3dmJqaQiqVgmEYOHv27LoP/cjICICVicRCoVB025EjR/DJJ58AQEM/YPTSSy8BWJmom52dta5TczDwTWKGpqenB6Ojo0ilUjh79qzfZVU0NzeH3t5e6/qVK1fKljHfUtN1vWH97tmzB6FQCP39/VhcXLT6oOZg4Bsgl8s5/h2JRKy3z5566ilEIhHrNjM0uVwO0Wi06H7m6Oq0Xqc2N2/L2e9XyvygzfPPP2+1vfrqq9an68yaEokEADi+H1+ptkrL2G9/4403AKDorTg366LaMfAN0NnZ6fj373//e0xOTkLTNExOTuLDDz+0bjND87e//Q1DQ0NF92tvb6+43kp9VaNpWtGypR9ZPXr0KADg17/+tbWMUgq7du3CxYsXoWka2tvb8a9//QvpdLrs/XinPjo7O8s+Dmtfxn57T08PDMOw1utmXVQf/ly0g8HBQQDYtD8mudnx8auMIzyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSCtfhewHm3duhWfffYZJiYm/C6F6vTOO+/4XcK6xK+4cnDz5s2qP2W80f31r38FAPzhD3/wuZLmOXLkCHbv3u13GesOAy8Qv/NNLr6GJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScShIEnEoSBJxKEgScSpNXvAqj5fvrpJywvL1vXl5aWAAD/+9//rLZAIIAnnnjC89rIW5pSSvldBDXPlStX8Jvf/MbVsv/+97/x/PPPN7ki8hNP6Te53bt3u152x44dTayE1gMGfpPr6OjA8ePH0dLSUnGZlpYWHD9+HB0dHR5WRn5g4AU4deoUqr1yU0rh1KlTHlZEfuFreAF+/PFH7Nixo2jizi4QCODu3bvYtm2bx5WR1zjCC7Bt2zbouo7W1vI3ZVpbW6HrOsMuBAMvxMmTJ/Hw4cOy9ocPH+LkyZM+VER+4Cm9EPfv38cvf/lL/PTTT0XtTzzxBP773/9i69atPlVGXuIIL8TWrVvR19eHQCBgtQUCAfT19THsgjDwgvT39xdN3C0vL6O/v9/HishrPKUX5OHDh+js7MTdu3cBrHzQJpvNVn2PnjYXjvCCtLS04OTJk2hra0NbWxtOnjzJsAvDwAszMDCApaUlLC0tYWBgwO9yyGPi/lvuT3/6E65fv+53GetCJBLxuwRf7d+/H3/+85/9LsNT4l7Da5oGAOjr6/O5Ev/88MMPWFpawq9+9Su/S/HN5OQkAFT9yPFmJG6EB4BYLMbTWeEmJiYwODjodxme42t4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGPgqcrkcEokEgsGg36UQNQQDX8W5c+fQ39+P6elp1/cpFArWl2x4pVAoYG5uDuPj43U/OWma5nipZm5uDiMjI9A0DSMjI5idnS3b/krrdXuZm5ur2n8t9RIDX9Xo6GjN97l06VITKqkuEong66+/xvvvv1/Tk5OdUgrZbNa6ns/nq34bzNzcHI4ePYre3l4opTA6OoodO3ZgaGiobNl4PA6llHWx92le4vG41ZbJZKxlPv/884o12G/LZrPivr2mLkoYACoWi9W0vNvdlM/nla7rrpdvtFpqXes6DMNwXC6VShW1Oy3j1Ec+ny+7XyQSUQBUJpMpW0cmk7Fur2ebY7GYb4+TnzjC1yEajULTNIyPjyOXy1mnkpFIxBphzVPM0nmA6elp6xR4YWEBAJBIJMraGi0cDiMcDjdsfYuLiwCAq1evFrX39PQUXbeP1tVs3769bNnjx48DAC5fvly2/OXLl63bqQZ+P+N4DWsc4SORiDXi5PN5FQqFykYm+3VzxAegUqmUUkqpZDKpACjDMFQymVRKrYxYZttatq3SQxoKhVQoFFrTOuzMkRyAGhsbU/l8viF12pdRqvKZhLmf3NZbSuoIL26L1xp4ACqbzVrXs9ls1cCvta0Wa71/retIp9NWIAGoeDzuKvi1BH5mZkYBsJ4YlVp5spmZmam5XjupgecpfY0Mw0BnZycSiQQKhQI6OjrEThZ1d3djdHQUyWQShmGgv78f7e3tdU8cOjl27BiA4gm6L7/80mqn2jDwNTpz5gx0XbcO7mg06ndJvjty5IgVfF3XEQwGGxr6eDyOCxcuYGFhAblcDi+88ELD1i0NA1+j7u5uTE1NIZVKwTAMnD17VlToR0ZGAKxMShYKhaLbjhw5gk8++QQAGvphpZdeegnAykTd7OysdZ1qx8DXyDzQe3p6MDo6ilQqhbNnz/pdlifm5ubQ29trXb9y5UrZMnv27AEA6LresH737NmDUCiE/v5+LC4uWn1Q7Rj4KnK5nOPfkUjEevvsqaeeKvqNNvNAz+VyiEajRfczR0Sn9Vbqyy37aFs68gLu3par1q/5QZvnn3/eanv11VetT9eZ/SYSCQDA+fPnV+2jUn9O++SNN94AgKK34ta6z0Tye9bQa6hhlh4/zwDDNhOMn2fpzQ99RCKRovuYb1eFQiFrBt9pHW7aatkmp4vdam/LVVpH6cWchTfXn06n1djYmHV7KBRS6XS67jqr3W5/y9LNuqqROksv8sck+dtyZP62nLDDn6f0RJIw8ESCiPy56I3A7b96SjslpbVh4NcpBpmagaf0RIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIIw8ESCMPBEgjDwRIKI/MYbAOjr6/O5EvLT5OQkAHn/lSju32P/+Mc/4vr1636X4atr164BAA4ePOhzJf7p6+vD/v37/S7Dc+JGeAIGBwcBALFYzOdKyGt8DU8kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTyQIA08kCANPJAgDTySIppRSfhdBzbO4uIjXXnsN7e3tVtv8/DwAoLu722rL5/OYnZ3F008/7XmN5J1Wvwug5rp79y6uXr3qeNsPP/xQdH1xcZGB3+Q4wgvw3HPP4fr161WX2b9/P7799luPKiK/8DW8AKdPn0YgEKh4eyAQwOnTp70riHzDEV6AGzdu4Nlnn626zHfffYd9+/Z5VBH5hSO8APv27cPhw4ehaVrZbZqm4fDhwwy7EAy8EMPDw2hpaSlrb2lpwfDwsA8VkR94Si/E7du38cwzz+DRo0dF7Vu2bMHi4iK6urp8qoy8xBFeiK6uLvT29haN8i0tLejt7WXYBWHgBRkcHHTVRpsXT+kFyefz6OjowPLyMoCVt+NyuVzRp/Boc+MIL0h7eztOnDiB1tZWtLa24sSJEwy7MAy8MENDQ3jw4AEePHiAoaEhv8shj/Gz9ABu3ryJubk5v8vwxNLSkvX3/fv3MTk56WM13jly5Ah2797tdxm+42t4AL/73e/w2Wef+V0GNdE777yDv//9736X4TuO8FgZ6QYGBhCLxfwuhZpgcHAQ9+/f97uMdYGv4YkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgGyiXyyGRSCAYDPpdCpEj/j98A507dw4XLlzwu4yaOf0ijSkSiaC7uxsvv/wytm/f7mFV1Awc4RtodHTU7xLqopRCNpu1rufzeSiloJTC8ePHMT4+jqGhIeRyOR+rpEZg4AkA0NHRYf1tH8l7enrw6aefAgDeffddFAoFz2ujxmHg16BQKCCRSEDTNASDQczPzzsul8vlEI1GreVmZ2etdvtr/unpaWuZhYWFonWY9x8fH0culys7Da/UBwCEw2GEw+G6t7OjowMffPABpqencenSpXW1bVQjRWpgYEANDAzUfD9d15VhGCqfzyullIrH4wqAsu/WbDardF1X8XhcKaXUzMyMAqBSqZTSdd1aPplMKqWUymQyCoAyDMNaRyQSUZlMRimlVD6fV6FQyHUfSikVCoVUKBRadXtKa7fL5/Nlda2HbXOj3sd3M2LgVX0HxNTUlAKg0um01WaGwn7Amk8CdgCsADqFrLQNgMpms9b1bDZbUx9uVQu80+0bZdsY+McYeFXfAWEYhmM4Sg9o+0hXenFa3qnN7Csej1tnE3ar9eFWrYHfKNvGwD/GwKv6DohKB53TCFZLiJza0ul00YEfiURc1VIrN6f09pF1o2wbA/8YJ+08UmlCz43u7m5MTU0hlUrBMAycPXsW0Wi0oX2s5sqVKwCAV155paH9rodtk4SBr9PY2BgA4OrVq66W++KLL6y3tMxZZ7c0TUOhUEBPTw9GR0eRSqVw9uzZhvZRTS6Xw1/+8hfouo5jx441tF+/t00cv08x1oN6TvnMGWdd161ZZnMGGbaZaHMSqvSSyWSKbjNfv9on/szJLPx8Km32k8lkik59q/WhlLtZenu/9tfS5oy7rutFk2vrZdvc4Cn9Ywy8qv+AyGQy1qSTYRhFbyHZw5HJZKy3mwzDsA7W0oO4Wls2m1WRSO4RIuIAAAbWSURBVMTxdW61PpRaPfBOgTIvkUjEelut0j7wc9vcYOAf449JYuW3xwDwt+U2KT6+j/E1PJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIAw8kSAMPJEgDDyRIPz12J9NTk7i9ddf97sMaoLJyUn09fX5Xca6wMAD2Lt3L5aXl/Hmm2/6XQo1yd69e/0uYV3gd9oJxO94k4uv4YkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRh4IkEYeCJBGHgiQRp9bsAaq6lpSVMTExgaWnJart+/ToAYGxszGpra2vDyZMn0drKQ2Iz05RSyu8iqHkuXbqE3t5eAEAgEAAAmA+5pmkAgOXlZQDAN998gxdffNGHKskrDPwmt7S0hJ07d+LevXtVl3vyySdx584dtLW1eVQZ+YGv4Te5trY2vPXWW9bo7iQQCOCtt95i2AVg4AUYHBy0TtudLC8vY2BgwMOKyC88pRfg0aNH6Orqwp07dxxv37lzJ27fvo0tW/j8v9nxERZgy5YtGBoacjxlb2trw9DQEMMuBB9lIQYGBoremjMtLS3xdF4QntILsm/fPnz//fdFbXv37sWNGzd8qoi8xhFekFOnThXN1gcCAQwNDflYEXmNI7wg6XQaBw8eLGq7du0aDhw44FNF5DWO8IIcOHAAhw4dgqZp0DQNhw4dYtiFYeCFGR4etgI/PDzsdznkMZ7SC3Pr1i3s3r0bAHDz5k3s2rXL54rIS5s+8Fu3bnV8O4qoVFtbG+7fv+93GU216QOvaRpef/11vtdsc+/ePWiahm3btvldyroxMTGBr776Cps8DjL+H76vrw99fX1+l0Hr2PLyMr766iu/y2g6TtoRCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCcLAEwnCwLuQy+WQSCQQDAb9LoVoTUT8P/xanTt3DhcuXPC7jLoVCgX85z//wT//+U9MT09jamqq5nWYPy3tJBKJoLu7Gy+//DK2b9++llKpyTjCuzA6Oup3CWsSiUTw9ddf4/3338f09HRd61BKIZvNWtfz+TyUUlBK4fjx4xgfH8fQ0BByuVyjyqYmYOAFOH/+PM6fP7/m9XR0dFh/20fynp4efPrppwCAd999F4VCYc19UXMw8A4KhQISiQQ0TUMwGMT8/LzjcrlcDtFo1FpudnbWare/5p+enraWWVhYKFqHef/x8XHkcrmyU+dKfTRaOBxGOByu+/4dHR344IMPMD09jUuXLhXdtpn204anNjkAKhaL1XQfXdeVYRgqn88rpZSKx+MKgLLvrmw2q3RdV/F4XCml1MzMjAKgUqmU0nXdWj6ZTCqllMpkMgqAMgzDWkckElGZTEYppVQ+n1ehUMh1H/Uo3Qa7UCikQqHQmtaRz+fLtnGj7KdYLFZxuzaTTb+FtQZ+ampKAVDpdNpqMw9k+wFhPgmU9mWGxikYpW0AVDabta5ns9ma+qhVtbA2ah0bdT8x8JtErYE3DMPxgS89CO2jU+nFaXmnNrOveDxunU3YrdZHrfwI/EbZTwz8JlFr4CsdKE6jTi0HvlNbOp0uOlgjkYirWurV7MCbZ0L2kXWj7Ccpgeek3RpVmtBzo7u7G1NTU0ilUjAMA2fPnkU0Gm1oH166cuUKAOCVV14pu437aZ3w+xmn2VDjCD82NuY44YOSUcRcLhQKWaeZ2WzWGn1Kl3dqA1B0ippKpWrqo1ZONTVqHebEma7rRe0bZT9JGeE3/RbWGnhzlljXdWtm2Jz1BR7PHpsTR6WXTCZTdJt5ANon/swJKPMgNfvJZDJFB2m1Pmpl79/pdbCbWfpK6zBn3HVdL5pc20j7iYHfJGoNvFIrB5Q5UWQYRtHbPvYDOpPJWG8RGYZhHWClB161NnMkgsNr02p91LoPnC52qwW+0jrMus231ZxshP0kJfAifkwyFovxxySpqomJCQwODm76H5PkpB2RIAw8kSD899gNqtq/q9pt9lNUqg0Dv0ExyFQPntITCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCcLAEwnCwBMJwsATCSLiG2+I3Nrkcdj8/x57+fJl3Lp1y+8yaAPYtWuX3yU03aYf4YnoMb6GJxKEgScShIEnEqQVwP/zuwgi8sb/B0zubLxc1/zxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "keras.utils.plot_model(model, to_file='plot.png', show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1703/1703 [==============================] - 774s 452ms/step - loss: 6.3921\n",
      "\n",
      "Epoch 00001: loss improved from inf to 6.39205, saving model to next_words.h5\n",
      "Epoch 2/20\n",
      "1703/1703 [==============================] - 750s 441ms/step - loss: 5.8096\n",
      "\n",
      "Epoch 00002: loss improved from 6.39205 to 5.80959, saving model to next_words.h5\n",
      "Epoch 3/20\n",
      "1703/1703 [==============================] - 737s 432ms/step - loss: 5.4788\n",
      "\n",
      "Epoch 00003: loss improved from 5.80959 to 5.47879, saving model to next_words.h5\n",
      "Epoch 4/20\n",
      "1703/1703 [==============================] - 717s 421ms/step - loss: 5.2062\n",
      "\n",
      "Epoch 00004: loss improved from 5.47879 to 5.20625, saving model to next_words.h5\n",
      "Epoch 5/20\n",
      "1703/1703 [==============================] - 756s 444ms/step - loss: 4.9698\n",
      "\n",
      "Epoch 00005: loss improved from 5.20625 to 4.96976, saving model to next_words.h5\n",
      "Epoch 6/20\n",
      "1703/1703 [==============================] - 809s 475ms/step - loss: 4.7468\n",
      "\n",
      "Epoch 00006: loss improved from 4.96976 to 4.74681, saving model to next_words.h5\n",
      "Epoch 7/20\n",
      "1703/1703 [==============================] - 797s 468ms/step - loss: 4.5163\n",
      "\n",
      "Epoch 00007: loss improved from 4.74681 to 4.51635, saving model to next_words.h5\n",
      "Epoch 8/20\n",
      "1703/1703 [==============================] - 750s 440ms/step - loss: 4.2782\n",
      "\n",
      "Epoch 00008: loss improved from 4.51635 to 4.27822, saving model to next_words.h5\n",
      "Epoch 9/20\n",
      "1703/1703 [==============================] - 815s 479ms/step - loss: 4.0367\n",
      "\n",
      "Epoch 00009: loss improved from 4.27822 to 4.03674, saving model to next_words.h5\n",
      "Epoch 10/20\n",
      "1703/1703 [==============================] - 588s 345ms/step - loss: 3.7870\n",
      "\n",
      "Epoch 00010: loss improved from 4.03674 to 3.78705, saving model to next_words.h5\n",
      "Epoch 11/20\n",
      "1703/1703 [==============================] - 678s 398ms/step - loss: 3.5406\n",
      "\n",
      "Epoch 00011: loss improved from 3.78705 to 3.54057, saving model to next_words.h5\n",
      "Epoch 12/20\n",
      "1703/1703 [==============================] - 644s 378ms/step - loss: 3.3020\n",
      "\n",
      "Epoch 00012: loss improved from 3.54057 to 3.30198, saving model to next_words.h5\n",
      "Epoch 13/20\n",
      "1703/1703 [==============================] - 601s 353ms/step - loss: 3.0703\n",
      "\n",
      "Epoch 00013: loss improved from 3.30198 to 3.07033, saving model to next_words.h5\n",
      "Epoch 14/20\n",
      "1703/1703 [==============================] - 670s 393ms/step - loss: 2.8437\n",
      "\n",
      "Epoch 00014: loss improved from 3.07033 to 2.84370, saving model to next_words.h5\n",
      "Epoch 15/20\n",
      "1703/1703 [==============================] - 653s 383ms/step - loss: 2.6213\n",
      "\n",
      "Epoch 00015: loss improved from 2.84370 to 2.62131, saving model to next_words.h5\n",
      "Epoch 16/20\n",
      "1703/1703 [==============================] - 693s 407ms/step - loss: 2.4043\n",
      "\n",
      "Epoch 00016: loss improved from 2.62131 to 2.40426, saving model to next_words.h5\n",
      "Epoch 17/20\n",
      "1703/1703 [==============================] - 558s 328ms/step - loss: 2.1874\n",
      "\n",
      "Epoch 00017: loss improved from 2.40426 to 2.18739, saving model to next_words.h5\n",
      "Epoch 18/20\n",
      "1703/1703 [==============================] - 559s 328ms/step - loss: 1.9781\n",
      "\n",
      "Epoch 00018: loss improved from 2.18739 to 1.97814, saving model to next_words.h5\n",
      "Epoch 19/20\n",
      "1703/1703 [==============================] - 610s 358ms/step - loss: 1.7755\n",
      "\n",
      "Epoch 00019: loss improved from 1.97814 to 1.77547, saving model to next_words.h5\n",
      "Epoch 20/20\n",
      "1703/1703 [==============================] - 677s 397ms/step - loss: 1.5898\n",
      "\n",
      "Epoch 00020: loss improved from 1.77547 to 1.58982, saving model to next_words.h5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x159d7f5db88>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"next_words.h5\", monitor='loss', verbose=1, save_best_only=True)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=0.001))\n",
    "model.fit(X, y, epochs=20, batch_size=64, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Prediction</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model = load_model('next_words.h5')\n",
    "tokenizer = pickle.load(open('token.pkl', 'rb'))\n",
    "\n",
    "def Predict_Next_Words(model, tokenizer, text):\n",
    "\n",
    "  sequence = tokenizer.texts_to_sequences([text])\n",
    "  sequence = np.array(sequence)\n",
    "  preds = np.argmax(model.predict(sequence))\n",
    "  predicted_word = \"\"\n",
    "  \n",
    "  for key, value in tokenizer.word_index.items():\n",
    "      if value == preds:\n",
    "          predicted_word = key\n",
    "          break\n",
    "  \n",
    "  print(predicted_word)\n",
    "  return predicted_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your line: us makes us stronger\n",
      "['makes', 'us', 'stronger']\n",
      "so\n",
      "Enter your line: us makes us stronger\n",
      "['makes', 'us', 'stronger']\n",
      "so\n",
      "Enter your line: us makes us stronger\n",
      "['makes', 'us', 'stronger']\n",
      "so\n",
      "Enter your line: us makes us stronger\n",
      "['makes', 'us', 'stronger']\n",
      "so\n",
      "Enter your line: 0\n",
      "Execution completed.....\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "  text = input(\"Enter your line: \")\n",
    "  \n",
    "  if text == \"0\":\n",
    "      print(\"Execution completed.....\")\n",
    "      break\n",
    "  \n",
    "  else:\n",
    "      try:\n",
    "          text = text.split(\" \")\n",
    "          text = text[-3:]\n",
    "          print(text)\n",
    "        \n",
    "          Predict_Next_Words(model, tokenizer, text)\n",
    "          \n",
    "      except Exception as e:\n",
    "        print(\"Error occurred: \",e)\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
